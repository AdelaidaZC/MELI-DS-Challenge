{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtención de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/adelaidazuluaga/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/adelaidazuluaga/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import regex\n",
    "import requests\n",
    "import unidecode\n",
    "import os, glob\n",
    "from pathlib import Path  \n",
    "import cv2\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "import shutil, sys\n",
    "import urllib.request\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descargar un total de 1000 datos por clase: 80% train, 20% test\n",
    "OFFSETS_TRAIN = list(range(0,700,50)) #700 datos\n",
    "OFFSETS_TEST = list(range(700,850,50)) #150 datos\n",
    "OFFSETS_VAL = list(range(850,1000,50)) #150 datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /Users/adelaidazuluaga/.pyenv/versions/3.10.5/lib/python3.10/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/adelaidazuluaga/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from sklearn) (1.1.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/adelaidazuluaga/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/adelaidazuluaga/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.8.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/adelaidazuluaga/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/adelaidazuluaga/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.23.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install plotly==5.10.0\n",
    "!pip install pillow\n",
    "!pip install regex\n",
    "!pip install Unidecode\n",
    "!pip install wordcloud\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = requests.get('https://api.mercadolibre.com/sites/MLA/categories')\n",
    "prod_categories= cats.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_json_items(json_cat,offset_input):\n",
    "    offset = offset_input #FIX ME : Set variable offset [0,50,100,150]\n",
    "    cat_id = json_cat['id']\n",
    "    cat_name = json_cat['name']\n",
    "    url = f'https://api.mercadolibre.com/sites/MLA/search?category={cat_id}&offset={offset}'\n",
    "    request = requests.get(url)\n",
    "    items = request.json()\n",
    "    return items, cat_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_json_items_iteratively(json_cat,offset_list):\n",
    "    results = []\n",
    "    offsets = offset_list\n",
    "    cat_id = json_cat['id']\n",
    "    cat_name = json_cat['name']\n",
    "    for off in offsets: \n",
    "        url = f'https://api.mercadolibre.com/sites/MLA/search?category={cat_id}&offset={off}'\n",
    "        request = requests.get(url)\n",
    "        data = request.json()\n",
    "        for element in data['results']:\n",
    "            results.append(element)\n",
    "    return results, cat_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_brand(items_cat):\n",
    "    brands = []\n",
    "    for att in items_cat['attributes']:\n",
    "        find_attr = att['id']\n",
    "        if 'BRAND' in find_attr or 'Brand' in find_attr:\n",
    "            brands.append(att['value_name'])\n",
    "            break\n",
    "    return brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_proc_nlp(text_df):\n",
    "    cleaned_df =[]\n",
    "    for text in text_df:\n",
    "        clean_text = regex.sub(r'\\&[a-z]+\\;', '', text)\n",
    "        clean_text = regex.sub(r\"\\n\", \" \", text)\n",
    "        clean_text = text.lower()\n",
    "        #clean_text = regex.sub('[0-9]+', ' NUMB ', clean_text)\n",
    "        clean_text = unidecode.unidecode(clean_text)\n",
    "        #clean_text = regex.sub(r'(NUMB\\s+)(NUMB\\s*)*', ' NUMB ', clean_text)\n",
    "        clean_text = regex.sub(r'\\s+', ' ', clean_text)\n",
    "        clean_text = regex.sub('[^a-zA-Z]', ' ', clean_text).strip(' ')\n",
    "        cleaned_df.append(clean_text)\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(text_name):\n",
    "    text = text_name\n",
    "    clean_text = regex.sub(r'\\&[a-z]+\\;', '', text)\n",
    "    clean_text = regex.sub(r\"\\n\", \" \", text)\n",
    "    clean_text = text.lower()\n",
    "    clean_text = unidecode.unidecode(clean_text)\n",
    "    clean_text = regex.sub(r'\\s+', ' ', clean_text)\n",
    "    clean_text = regex.sub('[^a-zA-Z]', ' ', clean_text).strip(' ')\n",
    "    cleaned_df = clean_text\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_categs(categories):\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(categories)\n",
    "    return integer_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_=[]\n",
    "for category in prod_categories:\n",
    "    categories_.append(category['name'])\n",
    "numeric_categories = encoding_categs(categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_categs = dict(zip(categories_,numeric_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pd_product(item_json,item_category, num_categs):\n",
    "    titles_=[]\n",
    "    marcas_=[]\n",
    "    image_=[]\n",
    "    items = item_json\n",
    "    for i in range(len(items)):\n",
    "        titles_.append(items[i]['title'].lower()) \n",
    "        marcas_.append(get_product_brand(items[i])) #extraer la marca\n",
    "        image_.append(items[i]['thumbnail'])\n",
    "    df_products = pd.DataFrame(columns=['nombre','categoria','marca','imagen'])\n",
    "    df_products['nombre'] = titles_\n",
    "    df_products['categoria'] = clean_name(item_category)\n",
    "    df_products['marca'] = marcas_\n",
    "    df_products['imagen'] = image_\n",
    "    df_products['nombre_preproc'] = pre_proc_nlp(df_products['nombre'])\n",
    "    df_products['numeric_category'] = dict_categs[item_category]\n",
    "    return df_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [10:58<00:00, 20.57s/it]\n"
     ]
    }
   ],
   "source": [
    "category_dict_train = {}\n",
    "category_dict_test = {}\n",
    "category_dict_val = {}\n",
    "for category in tqdm(prod_categories): \n",
    "    #obtener diccionario de elementos para train, test y val\n",
    "    item_json_train,item_category_train = obtain_json_items_iteratively(category,OFFSETS_TRAIN) #train\n",
    "    item_json_test,item_category_test = obtain_json_items_iteratively(category,OFFSETS_TEST) #test\n",
    "    item_json_val,item_category_val = obtain_json_items_iteratively(category,OFFSETS_VAL) #test\n",
    "    #train dataset \n",
    "    df_cat_prod_train = create_pd_product(item_json_train,item_category_train,numeric_categories)\n",
    "    category_dict_train[df_cat_prod_train['categoria'][0]] = df_cat_prod_train\n",
    "    #test dataset\n",
    "    df_cat_prod_test = create_pd_product(item_json_test,item_category_test,numeric_categories)\n",
    "    category_dict_test[df_cat_prod_test['categoria'][0]] = df_cat_prod_test\n",
    "    #val dataset\n",
    "    df_cat_prod_val = create_pd_product(item_json_val,item_category_val,numeric_categories)\n",
    "    category_dict_val[df_cat_prod_val['categoria'][0]] = df_cat_prod_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(image_route, category,name_folder):\n",
    "    for ind,img_url in enumerate(image_route):\n",
    "        url = img_url\n",
    "        file_name = category + str(ind) +'.jpg' \n",
    "        save_path = './images_'+name_folder+'/'+ category\n",
    "        # Check whether the specified path exists or not\n",
    "        isExist = os.path.exists(save_path)\n",
    "        if not isExist:\n",
    "          # Create a new directory because it does not exist \n",
    "          os.makedirs(save_path)\n",
    "        completeName = os.path.join(save_path, file_name)\n",
    "        if len(url)>0:\n",
    "            urllib.request.urlretrieve(url, completeName)\n",
    "        else: \n",
    "            print(ind,category)\n",
    "            print(url)\n",
    "            print(\"problema con url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [13:22<00:00, 25.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# Download images\n",
    "for cat_ in tqdm(category_dict_train.keys()):\n",
    "    download_images(category_dict_train[cat_]['imagen'],cat_,'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [03:18<00:00,  6.19s/it]\n"
     ]
    }
   ],
   "source": [
    "for cat_ in tqdm(category_dict_test.keys()):\n",
    "    download_images(category_dict_test[cat_]['imagen'],cat_,'test') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [03:20<00:00,  6.27s/it]\n"
     ]
    }
   ],
   "source": [
    "for cat_ in tqdm(category_dict_val.keys()):\n",
    "    download_images(category_dict_val[cat_]['imagen'],cat_,'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate whole dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_train = pd.concat([category_dict_train[cat] for cat in category_dict_train], axis=0)\n",
    "df_dataset_test = pd.concat([category_dict_test[cat] for cat in category_dict_test], axis=0)\n",
    "df_dataset_val = pd.concat([category_dict_val[cat] for cat in category_dict_val], axis=0)\n",
    "cwd = os.getcwd()\n",
    "filepath = Path(cwd+'/dataset_train_1.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "df_dataset_train.to_csv(filepath,index=False)  \n",
    "\n",
    "filepath = Path(cwd+'/dataset_test_1.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "df_dataset_test.to_csv(filepath,index=False)  \n",
    "\n",
    "filepath = Path(cwd+'/dataset_val_1.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "df_dataset_val.to_csv(filepath,index=False)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
